NLP -> compreensão natural e automatizar trabalhos de linguagem.

LLMs
----
RNN -> Recurrent Neural Networks ( Siri, Google assistent)
- Modelos antigos
- Problemas com perda de contexto (memória curta)

LSTM -> Long Short-Term Memory ( Siri, Google assistent )
- Modelos antigos
- Problemas com perda de contexto (memória curta)


Attention is all you need
-------------------------
- baseado em escopo e tokenização


Transformers
------------
- Encoder/Decoder
- Inputs / Outputs
    Outputs shifted right ->   
    Outputs probabilities ->
- correlação entre as palavras
- pontos com mais atenção em uma frase são mais focados


RNN para Transformers
--------------------
- primeira implementação no google translate
- 2019 impulso da transformação de RNN -> Transformers
- Modelo BERT

GPT -> Generative Pre-trained Transformers


Codex até Copilot
-----------------
GPT fine-tuned
Parceria com Github ( junho 2021 )
Anuncio do Copilot Chat ( dezembro 2023 )


Modelos Orion (o1, o1-mini, etc...)
-----------------
- Modelos mais novos da OpenAI usando Reasoning (chain-of-Throught)
- Resultados melhores
- Descarte de Tokens ( analisa, re-analisa e o que for fora do contexto exclui )


Dall-E
-------
- Multimodalidade de absorver e treinar dados
- Criador de imagens


Azure OpenAI
--------
RestAPI + Azure + OpenAI = Sucesso!
- totalmente privado


Copilot Chat
------------
Interface de interação com GitHub Copilot
Perguntas e respostas sobre o contexto do código
- Documentar dódigo
- Gerar casos de testes
- Escopo maior do código
    - Inline Chat -> diretamente no código (CTRL+i)
    - Chat View -> Chat com membros, agentes, workspaces. 
    - Quick Chat -> 
    
@ -> Contexto que é dado para o chat
# -> Referenciando algum arquivo (ex: #vendas.py)
/ -> Comando a ser mandado para o Chat

